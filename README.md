# Alya: Chatbot Inteligente para la Plataforma EmprendeYA

Este repositorio contiene el c√≥digo fuente de Alya, un asistente virtual conversacional dise√±ado para la plataforma **EmprendeYA**, una iniciativa de apoyo a emprendedores en Nari√±o, Colombia.

Alya utiliza el framework **Rasa Open Source** para su n√∫cleo de Comprensi√≥n del Lenguaje Natural (NLU) y gesti√≥n de di√°logo. Para responder preguntas espec√≠ficas y detalladas sobre la informaci√≥n de EmprendeYA, se ha implementado un sistema **RAG (Retrieval-Augmented Generation)**. Este sistema utiliza:

*   **Sentence Transformers** para la creaci√≥n de embeddings de texto.
*   **ChromaDB** como base de datos vectorial para almacenar y recuperar fragmentos de conocimiento relevantes.
*   **Ollama** para ejecutar Modelos de Lenguaje Grandes (LLMs) como **Mistral** de forma local, generando respuestas naturales basadas en el contexto recuperado.

El proyecto incluye una interfaz web simple (HTML, CSS, JavaScript) para demostraci√≥n y pruebas.

## üöÄ Caracter√≠sticas Principales

Alya puede:
*   **Responder preguntas frecuentes sobre EmprendeYA:**
    *   Qu√© es la plataforma y su prop√≥sito.
    *   Qui√©nes son sus autores.
    *   Detalles sobre sus secciones: Gesti√≥n de Proyectos, Academia EmprendeYA, Servicios Especializados, Mentor√≠a, Comunidad, Gu√≠a SECOP II, Blog, Herramientas Exclusivas.
    *   La visi√≥n futura de la plataforma.
*   **Manejar Chitchat B√°sico:** Saludos, agradecimientos, afirmaciones, negaciones y despedidas.
*   **Asistir en la Solicitud de Asesor√≠as:** Capturando informaci√≥n relevante como el tema de inter√©s (ej. marketing, finanzas), ubicaci√≥n y tipo de emprendimiento.
*   **Proporcionar Informaci√≥n General:** Sobre oportunidades disponibles, beneficios de la plataforma y c√≥mo registrarse.
*   **Utilizar RAG para Preguntas Abiertas:** Cuando una pregunta no coincide con un intent predefinido con alta confianza, Alya busca en su base de conocimiento (construida a partir del texto descriptivo de EmprendeYA) e intenta generar una respuesta utilizando un LLM local.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

*   **Rasa Open Source:** Framework principal para el chatbot.
*   **Python 3.10+:** Lenguaje de desarrollo.
*   **Ollama:** Para ejecutar LLMs locales (ej. Mistral 7B).
*   **ChromaDB:** Base de datos vectorial local.
*   **Sentence Transformers (`all-MiniLM-L6-v2`):** Para generar embeddings de texto.
*   **Librer√≠a `openai` de Python:** Como cliente para interactuar con la API compatible de Ollama.
*   **HTML, CSS, JavaScript:** Para la interfaz de chat web de demostraci√≥n.

## üèÅ C√≥mo Empezar

Sigue estos pasos para configurar y ejecutar Alya en tu m√°quina local.

### Requisitos Previos

1.  **Python** (versi√≥n 3.10 o superior recomendada). Aseg√∫rate de que est√© a√±adido al PATH.
2.  **Ollama** instalado y funcionando. Puedes descargarlo desde [ollama.ai](https://ollama.ai/).
3.  Un **Modelo LLM descargado** a trav√©s de Ollama. Este proyecto est√° configurado para usar `mistral` por defecto.
    ```bash
    ollama pull mistral
    ```
4.  (Opcional, pero recomendado si encuentras errores de compilaci√≥n) **Microsoft C++ Build Tools** (para Windows).

### Instalaci√≥n

1.  **Clona el Repositorio:**
    ```bash
    git clone https://URL_DE_TU_REPOSITORIO_AQUI.git
    cd nombre_de_la_carpeta_del_repositorio
    ```

2.  **Crea y Activa un Entorno Virtual:**
    ```bash
    python -m venv venv
    # Windows (PowerShell)
    .\venv\Scripts\Activate.ps1
    # Windows (CMD)
    # venv\Scripts\activate.bat
    # Linux/macOS
    # source venv/bin/activate
    ```

3.  **Instala las Dependencias:**
    (Aseg√∫rate de tener un archivo `requirements.txt` en la ra√≠z del proyecto. Si no, cr√©alo desde tu entorno de desarrollo con `pip freeze > requirements.txt` o instala manualmente las librer√≠as listadas en la secci√≥n de tecnolog√≠as).
    ```bash
    pip install -r requirements.txt
    ```
    Si no tienes `requirements.txt`, instala al menos:
    ```bash
    pip install rasa sentence-transformers chromadb openai
    ```

4.  **Indexa la Base de Conocimiento:**
    Este script procesar√° el texto de EmprendeYA (definido dentro del script) y crear√° la base de datos vectorial en una carpeta `chroma_db/`.
    ```bash
    python index_knowledge.py
    ```
    *Nota: Ejecuta este script solo una vez, o cada vez que actualices la informaci√≥n base en `index_knowledge.py`.*

5.  **Entrena el Modelo Rasa:**
    ```bash
    rasa train
    ```

## üöÄ C√≥mo Ejecutar el Bot

Necesitar√°s tener **tres terminales abiertas** (con el entorno virtual activado en las que ejecutan comandos de Rasa/Python).

1.  **Terminal X: Iniciar Servidor Ollama**
    ```bash
    ollama serve
    ```
    *Deja esta terminal corriendo. Deber√≠a indicar "Listening on 127.0.0.1:11434".*

2.  **Terminal 1: Iniciar Servidor de Acciones Rasa**
    (Navega a la carpeta del proyecto y activa venv si no lo has hecho)
    ```bash
    rasa run actions
    ```
    *Deja esta terminal corriendo. Verifica que cargue los embeddings, ChromaDB y el cliente Ollama sin errores.*

3.  **Terminal 2: Iniciar el Bot Rasa**
    (Navega a la carpeta del proyecto y activa venv si no lo has hecho)
    *   **Para interactuar por consola:**
        ```bash
        rasa shell
        ```
    *   **Para usar la interfaz web de demostraci√≥n (si la incluiste en el repo):**
        ```bash
        rasa run --enable-api --cors "*"
        ```
        Luego, abre el archivo `index.html` de la interfaz web en tu navegador. La interfaz se conectar√° a `http://localhost:5005`.

## üìÅ Estructura del Proyecto (Principales)

*   `actions/`: Contiene el c√≥digo Python para las acciones personalizadas (incluyendo la l√≥gica RAG).
*   `data/`: Archivos de entrenamiento NLU (`nlu.yml`), reglas (`rules.yml`) e historias (`stories.yml`).
*   `models/`: Donde Rasa guarda los modelos entrenados.
*   `chroma_db/`: Base de datos vectorial generada por `index_knowledge.py`. **Importante: Incluir en el `.gitignore` si no quieres subirla directamente al repo, pero es necesaria para ejecutar el RAG.**
*   `index_knowledge.py`: Script para procesar el texto de conocimiento y crear la base de datos vectorial.
*   `config.yml`: Configuraci√≥n del pipeline NLU y pol√≠ticas de di√°logo.
*   `domain.yml`: Definici√≥n de intents, entidades, slots, respuestas y acciones.
*   `endpoints.yml`: Configuraci√≥n de endpoints, como el servidor de acciones.
*   `requirements.txt`: (Recomendado) Lista de dependencias Python.
*   `(Opcional) web_interface/`: Carpeta con los archivos `index.html`, `style.css`, `script.js` para la demo web.

## üîÆ Pr√≥ximos Pasos y Mejoras Futuras

*   Refinar continuamente los datos de NLU para mayor precisi√≥n.
*   Implementar Rasa Forms para flujos de recopilaci√≥n de datos m√°s complejos (ej. agendar asesor√≠a con selecci√≥n de fecha/hora).
*   Mejorar el prompt enviado al LLM para respuestas a√∫n m√°s controladas.
*   Explorar diferentes modelos LLM a trav√©s de Ollama.
*   Integrar con canales de mensajer√≠a reales.
*   A√±adir m√°s capacidades y conocimientos a la base de EmprendeYA.

    Nota sobre `chroma_db/`:** Esta carpeta es generada por `index_knowledge.py` y contiene la base de datos vectorial. No est√° incluida en el repositorio para mantenerlo ligero. Deber√°s ejecutar `python index_knowledge.py` para crearla despu√©s de instalar las dependencias.

---

*Desarrollado con ‚ù§Ô∏è para el proyecto EmprendeYA.*
